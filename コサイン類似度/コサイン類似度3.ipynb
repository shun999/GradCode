{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\workspace\\practice\\env2\\lib\\site-packages (4.25.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: sentencepiece in c:\\workspace\\practice\\env2\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: fugashi in c:\\workspace\\practice\\env2\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: ipadic in c:\\workspace\\practice\\env2\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: gensim in c:\\workspace\\practice\\env2\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: filelock in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\workspace\\practice\\env2\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\workspace\\practice\\env2\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\workspace\\practice\\env2\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\workspace\\practice\\env2\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\workspace\\practice\\env2\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\workspace\\practice\\env2\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\workspace\\practice\\env2\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\practice\\env2\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\practice\\env2\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\practice\\env2\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers sentencepiece fugashi ipadic gensim\n",
    "from transformers import BertJapaneseTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "\n",
    "class SentenceBertJapanese:\n",
    "    def __init__(self, model_name_or_path, device=None):\n",
    "        self.tokenizer = BertJapaneseTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.model = BertModel.from_pretrained(model_name_or_path)\n",
    "        self.model.eval()\n",
    "\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(device)\n",
    "        self.model.to(device)\n",
    "\n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, sentences, batch_size=8):\n",
    "        all_embeddings = []\n",
    "        iterator = range(0, len(sentences), batch_size)\n",
    "        for batch_idx in iterator:\n",
    "            batch = sentences[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "            encoded_input = self.tokenizer.batch_encode_plus(batch, padding=\"longest\", \n",
    "                                           truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "            model_output = self.model(**encoded_input)\n",
    "            sentence_embeddings = self._mean_pooling(model_output, encoded_input[\"attention_mask\"]).to('cpu')\n",
    "\n",
    "            all_embeddings.extend(sentence_embeddings)\n",
    "\n",
    "        # return torch.stack(all_embeddings).numpy()\n",
    "        return torch.stack(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\WorkSpace\\Practice\\env2\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\thisi\\.cache\\huggingface\\hub\\models--tohoku-nlp--bert-base-japanese. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at tohoku-nlp/bert-base-japanese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#model = SentenceBertJapanese(\"sonoisa/sentence-bert-base-ja-mean-tokens\")\n",
    "#model = SentenceBertJapanese(\"sonoisa/sentence-bert-base-ja-mean-tokens-v2\")\n",
    "model = SentenceBertJapanese(\"tohoku-nlp/bert-base-japanese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_docs = [\n",
    "    '動物行動学者コンラート・ローレンツは、動物が大好き',\n",
    "    '幼い頃から動物に囲まれて育った',\n",
    "    '大人になっても、彼の屋敷ではカラス、オウム、ガン、サルなどの動物が放し飼いにされていた',\n",
    "    'ただ、中には大型で危険な動物たちもいるし、屋敷には幼い長女もいる',\n",
    "    '子供と一緒にするわけにはいかない',\n",
    "    'そこで娘を守るために庭に檻をつくって入れた',\n",
    "    '動物ではなく娘を、である',\n",
    "    '私は猫が大好きです',\n",
    "    '彼は犬が好きです',\n",
    "    '彼は犬が大好きです',\n",
    "    '彼は猫が好きです',\n",
    "    '彼は猫が大好きです',\n",
    "]\n",
    "vecs = model.encode(input_docs, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文章</th>\n",
       "      <th>類似度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>動物行動学者コンラート・ローレンツは、動物が大好き</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>幼い頃から動物に囲まれて育った</td>\n",
       "      <td>0.780914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>大人になっても、彼の屋敷ではカラス、オウム、ガン、サルなどの動物が放し飼いにされていた</td>\n",
       "      <td>0.821809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ただ、中には大型で危険な動物たちもいるし、屋敷には幼い長女もいる</td>\n",
       "      <td>0.786020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>子供と一緒にするわけにはいかない</td>\n",
       "      <td>0.722192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>そこで娘を守るために庭に檻をつくって入れた</td>\n",
       "      <td>0.765243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>動物ではなく娘を、である</td>\n",
       "      <td>0.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>私は猫が大好きです</td>\n",
       "      <td>0.846038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>彼は犬が好きです</td>\n",
       "      <td>0.850346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>彼は犬が大好きです</td>\n",
       "      <td>0.845109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>彼は猫が好きです</td>\n",
       "      <td>0.849396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>彼は猫が大好きです</td>\n",
       "      <td>0.846398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             文章       類似度\n",
       "0                     動物行動学者コンラート・ローレンツは、動物が大好き  1.000000\n",
       "1                               幼い頃から動物に囲まれて育った  0.780914\n",
       "2   大人になっても、彼の屋敷ではカラス、オウム、ガン、サルなどの動物が放し飼いにされていた  0.821809\n",
       "3              ただ、中には大型で危険な動物たちもいるし、屋敷には幼い長女もいる  0.786020\n",
       "4                              子供と一緒にするわけにはいかない  0.722192\n",
       "5                         そこで娘を守るために庭に檻をつくって入れた  0.765243\n",
       "6                                  動物ではなく娘を、である  0.757000\n",
       "7                                     私は猫が大好きです  0.846038\n",
       "8                                      彼は犬が好きです  0.850346\n",
       "9                                     彼は犬が大好きです  0.845109\n",
       "10                                     彼は猫が好きです  0.849396\n",
       "11                                    彼は猫が大好きです  0.846398"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = F.cosine_similarity(vecs[0], vecs).tolist()\n",
    "pd.DataFrame({'文章': input_docs, '類似度': sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
